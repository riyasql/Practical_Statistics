{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Quiz 1:__ Use your results from the judicial dataset to match each description to the correct corresponding value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_judicial= pd.read_csv('judicial_dataset_predictions.csv')\n",
    "df_parachute = pd.read_csv('parachute_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7283 entries, 0 to 7282\n",
      "Data columns (total 3 columns):\n",
      "defendant_id    7283 non-null int64\n",
      "actual          7283 non-null object\n",
      "predicted       7283 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 170.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_judicial.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>defendant_id</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22574</td>\n",
       "      <td>innocent</td>\n",
       "      <td>innocent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>35637</td>\n",
       "      <td>innocent</td>\n",
       "      <td>innocent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>39919</td>\n",
       "      <td>innocent</td>\n",
       "      <td>innocent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29610</td>\n",
       "      <td>guilty</td>\n",
       "      <td>guilty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>38273</td>\n",
       "      <td>innocent</td>\n",
       "      <td>innocent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   defendant_id    actual predicted\n",
       "0         22574  innocent  innocent\n",
       "1         35637  innocent  innocent\n",
       "2         39919  innocent  innocent\n",
       "3         29610    guilty    guilty\n",
       "4         38273  innocent  innocent"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_judicial.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__if everyone was predicted to be guilty, the proportion of Type 1 Errors made?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets find out the count of those who are innocent and guilty in the predicted column\n",
    "predict_all = df_judicial['predicted'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets find the out the count of those who are innocent from actual colum\n",
    "actual_innoc = df_judicial[df_judicial['actual']=='innocent']['actual'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of Type 1 error is 0.45159961554304545%\n"
     ]
    }
   ],
   "source": [
    "#porpotion of Type 1 error is the count of those who are innocent from actual colum \n",
    "#devided by the count of all who are in predicted column\n",
    "print(\"Proportion of Type 1 error is {}%\".format(actual_innoc / predict_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Percentage of Errors__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>defendant_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">guilty</td>\n",
       "      <td>guilty</td>\n",
       "      <td>3698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>innocent</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">innocent</td>\n",
       "      <td>guilty</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>innocent</td>\n",
       "      <td>3278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    defendant_id\n",
       "actual   predicted              \n",
       "guilty   guilty             3698\n",
       "         innocent            296\n",
       "innocent guilty               11\n",
       "         innocent           3278"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets use groupby to split and agregate and find the count\n",
    "df_actual = df_judicial.groupby(['actual','predicted']).count()\n",
    "df_actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above grouped table we can identify that there are 11 actual innocents people who made guilty by the judges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So the percentage of Type 1 error is 0.001510366607167376\n"
     ]
    }
   ],
   "source": [
    "print(\"So the percentage of Type 1 error is {}\".format((11 / 7283)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And the percentage of Type 2 error is 0.04064259233832212\n"
     ]
    }
   ],
   "source": [
    "print(\"And the percentage of Type 2 error is {}\".format((296 / 7283)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Total Percentage of error__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total percentage of errors is 0.042152958945489497\n"
     ]
    }
   ],
   "source": [
    "print(\"The total percentage of errors is {}\".format((307 / 7283)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Quiz 2:__ Use your results from the parachute dataset to match each description to the correct corresponding value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5829 entries, 0 to 5828\n",
      "Data columns (total 3 columns):\n",
      "parachute_id    5829 non-null int64\n",
      "actual          5829 non-null object\n",
      "predicted       5829 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 136.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_parachute.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>parachute_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">fails</td>\n",
       "      <td>fails</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>opens</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">opens</td>\n",
       "      <td>fails</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>opens</td>\n",
       "      <td>5549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  parachute_id\n",
       "actual predicted              \n",
       "fails  fails                47\n",
       "       opens                 1\n",
       "opens  fails               232\n",
       "       opens              5549"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets use groupby to split and agregate, also find the count\n",
    "df_open = df_parachute.groupby(['actual','predicted']).count()\n",
    "df_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So the percentage of Type 1 error is 0.00017155601303825698\n"
     ]
    }
   ],
   "source": [
    "print(\"So the percentage of Type 1 error is {}\".format((1 / 5829)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And the percentage of Type 2 error is 0.03980099502487562\n"
     ]
    }
   ],
   "source": [
    "print(\"And the percentage of Type 2 error is {}\".format((232 / 5829)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Total Percentage of error__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total percentage of errors is 0.039972551037913875\n"
     ]
    }
   ],
   "source": [
    "print(\"The total percentage of errors is {}\".format((233 / 5829)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If every parachute was predicted to not open, the proportion of type 1 error is zero, because this is a type 2 error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
